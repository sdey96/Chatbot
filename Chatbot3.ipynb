{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNLIl+UurbyFoDj1gTogg5S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"z3cC7hMftl1n"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import nltk\n","import string\n","import re\n","import random\n","from datetime import datetime\n","import glob"]},{"cell_type":"code","source":["# Download necessary NLTK resources\n","nltk.download('punkt')\n","nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Bj5JCCNt2yV","executionInfo":{"status":"ok","timestamp":1721924811503,"user_tz":-330,"elapsed":1432,"user":{"displayName":"Subhadeep Dey","userId":"03492811423952281481"}},"outputId":"38663d1b-b989-40a5-fff5-d26d53fd0596"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["# Load and preprocess data from multiple .txt files\n","file_paths = glob.glob('*.txt')  # This will match all .txt files in the current directory\n","raw_docs = []"],"metadata":{"id":"Hs_zyES_t5bD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for file_path in file_paths:\n","    with open(file_path, 'r', errors='ignore') as f:\n","        raw_docs.append(f.read().lower())"],"metadata":{"id":"BrbQjtNs38YF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Combine all text data into a single string\n","combined_raw_doc = ' '.join(raw_docs)"],"metadata":{"id":"Ny17lB5O4Bfm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenization and lemmatization\n","lemmatizer = nltk.stem.WordNetLemmatizer()\n","tokens = nltk.word_tokenize(combined_raw_doc)\n","punctuation_removal = dict((ord(punctuation), None) for punctuation in string.punctuation)"],"metadata":{"id":"8qj1CEQBuPyV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def LemNormalize(text):\n","    return nltk.word_tokenize(re.sub(r'[^\\w\\s]', '', text.lower()))"],"metadata":{"id":"J0gKzAf-uSzX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Store sentences for searching\n","sent_tokens = nltk.sent_tokenize(combined_raw_doc)"],"metadata":{"id":"24k115shuVnO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Expanded greetings, responses, and \"How are you?\" handling\n","greetings = [\n","    \"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\", \"hey\",\n","    \"howdy\", \"good day\", \"yo\", \"hi there\", \"hiya\"\n","]\n","greeting_responses = [\n","    \"Hi there!\", \"Hey!\", \"*nods*\", \"Hello!\", \"Greetings!\", \"Hi!\",\n","    \"Howdy!\", \"Good day to you!\", \"Yo!\", \"Hi there!\", \"Hello, how can I help?\"\n","]"],"metadata":{"id":"lb4MTkzXuYZk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["how_are_you_phrases = [\n","    \"how are you\", \"how's it going\", \"how do you do\", \"how are things\"\n","]\n","how_are_you_responses = [\n","    \"I'm just a program, but I'm functioning as expected! How about you?\",\n","    \"I'm here to assist you! How can I help today?\",\n","    \"Doing well, thank you! What can I do for you today?\",\n","    \"All systems operational! How are you?\"\n","]"],"metadata":{"id":"_CEckYZsubHv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def greet(sentence):\n","    for word in sentence.split():\n","        if word.lower() in greetings:\n","            return random.choice(greeting_responses)\n","        elif any(phrase in sentence.lower() for phrase in how_are_you_phrases):\n","            return random.choice(how_are_you_responses)"],"metadata":{"id":"RXBqJ3vUuddB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Simple keyword-based response generation\n","def find_answer(user_response):\n","    user_response = LemNormalize(user_response)\n","    best_match = \"\"\n","    max_overlap = 0\n","    for sentence in sent_tokens:\n","        tokenized_sentence = LemNormalize(sentence)\n","        common_words = set(user_response).intersection(set(tokenized_sentence))\n","        if len(common_words) > max_overlap:\n","            max_overlap = len(common_words)\n","            best_match = sentence\n","    return best_match if best_match else \"I am sorry, I don't have information on that.\""],"metadata":{"id":"P5cJt5eYug2Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Recognizing and responding to date queries\n","def handle_special_queries(user_response):\n","    date_phrases = [\"what is the date\", \"what's the date\", \"today's date\", \"current date\", \"what date is it\"]\n","    if any(phrase in user_response for phrase in date_phrases):\n","        return f\"Today's date is {datetime.now().strftime('%B %d, %Y')}.\"\n","    return None"],"metadata":{"id":"4U2UD-DuwmPo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Context and sentiment analysis\n","context = {}\n","def set_context(user, context_data):\n","    context[user] = context_data\n","\n","def get_context(user):\n","    return context.get(user, {})"],"metadata":{"id":"TtRiIx77ukhQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fallback and clarification\n","def fallback():\n","    return \"I'm not sure I understand. Could you please rephrase?\"\n","\n","def clarify():\n","    return \"Do you mean...?\""],"metadata":{"id":"-Wt10M0uumqQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Main chatbot loop\n","def chatbot():\n","    flag = True\n","    print(\"Ruby: My name is Ruby. Let's have a conversation! Also, if you want to exit any time, just type Bye!\")\n","\n","    while flag:\n","        user_response = input().lower()\n","        if user_response != 'bye':\n","            if user_response in ('thanks', 'thank you'):\n","                flag = False\n","                print(\"Ruby: You're welcome!\")\n","            else:\n","                greeting_response = greet(user_response)\n","                if greeting_response:\n","                    print(\"Ruby:\", greeting_response)\n","                else:\n","                    special_response = handle_special_queries(user_response)\n","                    if special_response:\n","                        print(\"Ruby:\", special_response)\n","                    else:\n","                        response_text = find_answer(user_response)\n","                        print(\"Ruby:\", response_text)\n","        else:\n","            flag = False\n","            print(\"Ruby: Bye! Take care...\")"],"metadata":{"id":"mk5E-P4Mupu8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chatbot()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"htQlE1ZkusRn","executionInfo":{"status":"ok","timestamp":1721927815676,"user_tz":-330,"elapsed":86809,"user":{"displayName":"Subhadeep Dey","userId":"03492811423952281481"}},"outputId":"c8019a5e-df34-483c-df4c-7c12477d0b3f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ruby: My name is Ruby. Let's have a conversation! Also, if you want to exit any time, just type Bye!\n","hello\n","Ruby: Hello!\n","how are you\n","Ruby: All systems operational! How are you?\n","well\n","Ruby: for example, towers of hanoi is well understood using recursive implementation.\n","what is random forest\n","Ruby: for classification tasks, the output of the random forest is the class selected by most trees.\n","what is decision tree\n","Ruby: the left tree is the decision tree we obtain from using information gain to split the nodes and the right tree is what we obtain from using the phi function to split the nodes.\n","what is the date\n","Ruby: Today's date is July 25, 2024.\n","bye\n","Ruby: Bye! Take care...\n"]}]}]}